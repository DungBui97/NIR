# NIR Spectroscopy Analysis - PLS Models & Inference API

This repository contains code and models for Near-Infrared (NIR) spectroscopy analysis using Partial Least Squares (PLS) regression to predict various quality parameters of pepper samples.

## ğŸš€ Quick Start

### Option 1: Use the API with Docker (Recommended)
```bash
# Start the API with Docker Compose
cd my_app
docker-compose up -d

# Test the API
curl -X POST "http://localhost:8000/predict/all" -F "file=@Hadanard1_119012_20221216_094813.csv"
```

### Option 2: Use the API without Docker
```bash
cd my_app
pip install -r requirements.txt
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

Then access:
- API: http://localhost:8000
- Swagger UI: http://localhost:8000/docs

### Option 3: Use Jupyter Notebook
```bash
jupyter notebook Code.ipynb
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ my_app/                     # API Application
â”‚   â”œâ”€â”€ app.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py              # API configuration
â”‚   â”œâ”€â”€ test_api.py            # API testing script
â”‚   â”œâ”€â”€ start_api.sh           # Startup script
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ API_README.md          # API documentation
â”‚   â”œâ”€â”€ Dockerfile             # Docker configuration
â”‚   â””â”€â”€ docker-compose.yml     # Docker Compose setup
â”œâ”€â”€ Code.ipynb                 # Main analysis notebook
â”œâ”€â”€ mean_by_ma_mau.csv        # Input data file
â”œâ”€â”€ mo_hinh/                   # Trained models directory
    â”œâ”€â”€ do_am.pkl             # Moisture content model
    â”œâ”€â”€ tro_tong.pkl          # Total ash content model
    â”œâ”€â”€ tro_khong_tan.pkl     # Acid-insoluble ash model
    â”œâ”€â”€ piperin.pkl           # Piperine content model
    â”œâ”€â”€ Tinh_dau.pkl          # Essential oil model
    â”œâ”€â”€ random_forest_3regions_smote.pkl  # Origin classification model
    â””â”€â”€ label_encoder_3regions_smote.pkl  # Label encoder for regions
```

## Overview

This project uses NIR spectroscopy data to predict quality parameters in pepper samples using PLS regression with variable selection. The analysis includes data preprocessing, model optimization, and result validation.

## ğŸ“Š Quality Parameters Analyzed

1. **Äá»™ áº©m (Moisture Content)**: 10-13%
2. **Tro tá»•ng (Total Ash)**: 3-7%  
3. **Tro khÃ´ng tan (Acid-insoluble Ash)**: 0.5-1.5%
4. **Piperin (Piperine Content)**: 2-4%
5. **Tinh dáº§u (Essential Oil)**: 1-4%

## ğŸ”¬ API Usage

### 1. Predict All Parameters (with Standards Classification)
```bash
curl -X POST "http://localhost:8000/predict/all" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Response includes:
- All 5 chemical parameters
- Origin classification (3 regions)
- TCVN standard classification
- ESA standard classification

### 2. Predict TCVN & ESA Standards Only
```bash
curl -X POST "http://localhost:8000/predict/standards" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Returns:
- **TCVN Classification**: Based on moisture (â‰¤13%), ash (â‰¤7%), essential oil (â‰¥2.0ml/100g), piperine (â‰¥4%)
- **ESA Classification**: Based on moisture (â‰¤12%), ash (â‰¤7%), acid-insoluble ash (â‰¤1.5%), essential oil (â‰¥2.0ml/100g)

### 3. Classify Pepper Quality (Physical Standards)
```bash
curl -X POST "http://localhost:8000/classify/pepper_quality?tap_chat_la=0.4&hat_lep=5.5&hat_dau_dinh_vo=1.8&khoi_luong_theo_the_tich=560"
```

Parameters:
- `tap_chat_la`: Foreign matter (%)
- `hat_lep`: Light berries (%)
- `hat_dau_dinh_vo`: Pinheads/broken (%)
- `khoi_luong_theo_the_tich`: Bulk density (g/l)

Returns classification: **Loáº¡i 1**, **Loáº¡i 2**, **Loáº¡i 3**, or **KhÃ´ng Ä‘áº¡t tiÃªu chuáº©n**

### 4. Predict Origin Classification
```bash
curl -X POST "http://localhost:8000/predict/origin_classification" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Returns top 3 predictions with confidence scores for regions: Quáº£ng Trá»‹, Äáº¯k Láº¯k, Gia Lai

### 5. Predict Single Chemical Parameter
```bash
curl -X POST "http://localhost:8000/predict/do_am" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Available models: `do_am`, `tro_tong`, `tro_khong_tan`, `piperin`, `Tinh_dau`

### Test the API
```bash
cd my_app
python test_api.py
```

See [my_app/API_README.md](my_app/API_README.md) for detailed API documentation.

## ğŸ³ Docker Deployment

```bash
# Build and run with Docker Compose
cd my_app
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

## ğŸ“‹ API Endpoints Summary

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information and available models |
| `/predict/all` | POST | Predict all parameters + standards classification |
| `/predict/standards` | POST | TCVN & ESA standards classification only |
| `/predict/origin_classification` | POST | Origin classification (3 regions) |
| `/predict/{model_key}` | POST | Single parameter prediction |
| `/classify/pepper_quality` | POST | Physical quality grading (Loáº¡i 1, 2, 3) |
| `/health` | GET | Health check |
| `/docs` | GET | Interactive API documentation (Swagger UI) |

## Data Source

- **Input Data**: `mean_by_ma_mau.csv`
  - Contains averaged NIR spectral data by sample code (`ma_mau`)
  - Spectral range: typically 838-1750 nm
  - Quality parameters in the last 5 columns

## How to Use

### 1. Open the Analysis Notebook
```bash
jupyter notebook Code.ipynb
```

### 2. Run the Analysis Sections

The notebook is organized into the following sections:

#### Data Preprocessing
- Load and clean data from `mean_by_ma_mau.csv`
- Apply Savitzky-Golay filter with 2nd derivative
- Handle infinite values and missing data

#### Model Development
For each quality parameter, the notebook:
- Applies PLS variable selection with cross-validation
- Optimizes number of components and wavelength selection
- Fits the final model with range constraints
- Saves the trained model to `mo_hinh/` folder

#### Key Functions
- `pls_variable_selection()`: Optimizes PLS components and wavelength selection
- `RangeRandomizerRegressor`: Wrapper class that constrains predictions within valid ranges
- `print_wavelengths_kept()`: Shows which wavelengths are retained in the final model

### 3. Model Results

Each model section provides:
- Optimal number of PLS components
- Number of wavelengths selected
- Cross-validation RÂ² and MSE
- Calibration RÂ² and MSE
- Scatter plot of actual vs predicted values

### 4. Saved Models

Trained models are saved in the `mo_hinh/` folder:
- Models include both the PLS core and range constraints
- Can be loaded using `joblib.load()` for predictions
- Each model is optimized for its specific quality parameter range

## Model Performance Metrics

The analysis reports:
- **RÂ² Calibration**: Coefficient of determination for training data
- **RÂ² CV**: Cross-validation coefficient of determination  
- **MSE Calibration**: Mean squared error for training data
- **MSE CV**: Cross-validation mean squared error

## Requirements

```python
numpy
pandas
matplotlib
scikit-learn
scipy
joblib
```

## Usage Example

```python
import joblib
import numpy as np
from scipy.signal import savgol_filter

# Load a trained model
model = joblib.load('mo_hinh/do_am.pkl')

# Prepare new spectral data (apply same preprocessing)
X_new = savgol_filter(X_raw, 15, polyorder=2, deriv=2)
X_new_selected = X_new[:, kept_wavelength_indices]

# Make predictions
predictions = model.predict(X_new_selected)
```

## Notes

- All models use 2nd derivative Savitzky-Golay preprocessing (window=15, polyorder=2)
- Cross-validation uses 10-fold CV with shuffling
- Variable selection removes less important wavelengths to improve model robustness
- Range constraints ensure predictions stay within physically meaningful bounds
- Models are trained on averaged data by sample code to reduce noise

## Contact

For questions about the analysis or models, please refer to the detailed code in `Code.ipynb`.
