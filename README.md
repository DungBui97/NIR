# NIR Spectroscopy Analysis - PLS Models & Inference API

This repository contains code and models for Near-Infrared (NIR) spectroscopy analysis using Partial Least Squares (PLS) regression to predict various quality parameters of pepper samples.

## üöÄ Quick Start

### Option 1: Use the API (Recommended)
```bash
# Start the API server
cd my_app
./start_api.sh

# Or manually:
cd my_app
pip install -r requirements.txt
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

Then access:
- API: http://localhost:8000
- Swagger UI: http://localhost:8000/docs

### Option 2: Use Jupyter Notebook
```bash
jupyter notebook Code.ipynb
```

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ my_app/                     # API Application
‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # API configuration
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py            # API testing script
‚îÇ   ‚îú‚îÄ‚îÄ start_api.sh           # Startup script
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ API_README.md          # API documentation
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile             # Docker configuration
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml     # Docker Compose setup
‚îú‚îÄ‚îÄ Code.ipynb                 # Main analysis notebook
‚îú‚îÄ‚îÄ mean_by_ma_mau.csv        # Input data file
‚îú‚îÄ‚îÄ mo_hinh/                   # Trained models directory
    ‚îú‚îÄ‚îÄ do_am.pkl             # Moisture content model
    ‚îú‚îÄ‚îÄ tro_tong.pkl          # Total ash content model
    ‚îú‚îÄ‚îÄ tro_khong_tan.pkl     # Acid-insoluble ash model
    ‚îú‚îÄ‚îÄ piperin.pkl           # Piperine content model
    ‚îú‚îÄ‚îÄ Tinh_dau.pkl          # Essential oil model
    ‚îú‚îÄ‚îÄ random_forest_3regions_smote.pkl  # Origin classification model
    ‚îî‚îÄ‚îÄ label_encoder_3regions_smote.pkl  # Label encoder for regions
```

## Overview

This project uses NIR spectroscopy data to predict quality parameters in pepper samples using PLS regression with variable selection. The analysis includes data preprocessing, model optimization, and result validation.

## üìä Quality Parameters Analyzed

### Chemical Parameters
1. **ƒê·ªô ·∫©m (Moisture Content)**: 10-13%
2. **Tro t·ªïng (Total Ash)**: 3-7%  
3. **Tro kh√¥ng tan (Acid-insoluble Ash)**: 0.5-1.5%
4. **Piperin (Piperine Content)**: 2-4%
5. **Tinh d·∫ßu (Essential Oil)**: 1-4%

### Origin Classification
- **3 Main Regions**: Qu·∫£ng Tr·ªã, ƒê·∫Øk L·∫Øk, Gia Lai
- **Model**: Random Forest with SMOTE (95.17% accuracy)

## üî¨ API Usage

### 1. Predict All Parameters (with Standards Classification)
```bash
curl -X POST "http://localhost:8000/predict/all" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Response includes:
- All 5 chemical parameters
- Origin classification (3 regions)
- TCVN standard classification
- ESA standard classification

### 2. Predict TCVN & ESA Standards Only
```bash
curl -X POST "http://localhost:8000/predict/standards" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Returns:
- **TCVN Classification**: Based on moisture (‚â§13%), ash (‚â§7%), essential oil (‚â•2.0ml/100g), piperine (‚â•4%)
- **ESA Classification**: Based on moisture (‚â§12%), ash (‚â§7%), acid-insoluble ash (‚â§1.5%), essential oil (‚â•2.0ml/100g)

### 3. Classify Pepper Quality (Physical Standards)
```bash
curl -X POST "http://localhost:8000/classify/pepper_quality?tap_chat_la=0.4&hat_lep=5.5&hat_dau_dinh_vo=1.8&khoi_luong_theo_the_tich=560"
```

Parameters:
- `tap_chat_la`: Foreign matter (%)
- `hat_lep`: Light berries (%)
- `hat_dau_dinh_vo`: Pinheads/broken (%)
- `khoi_luong_theo_the_tich`: Bulk density (g/l)

Returns classification: **Lo·∫°i 1**, **Lo·∫°i 2**, **Lo·∫°i 3**, or **Kh√¥ng ƒë·∫°t ti√™u chu·∫©n**

### 4. Predict Origin Classification
```bash
curl -X POST "http://localhost:8000/predict/origin_classification" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Returns top 3 predictions with confidence scores for regions: Qu·∫£ng Tr·ªã, ƒê·∫Øk L·∫Øk, Gia Lai

### 5. Predict Single Chemical Parameter
```bash
curl -X POST "http://localhost:8000/predict/do_am" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_nir_data.csv"
```

Available models: `do_am`, `tro_tong`, `tro_khong_tan`, `piperin`, `Tinh_dau`

### Test the API
```bash
cd my_app
python test_api.py
```

## üèÜ Model Performance

### Origin Classification (Random Forest with SMOTE)
- **Overall Accuracy**: 95.17%
- **Qu·∫£ng Tr·ªã**: 96.31% accuracy (11,788 samples)
- **ƒê·∫Øk L·∫Øk**: 94.32% accuracy (5,708 samples)
- **Gia Lai**: 92.84% accuracy (3,730 samples)

### Standards Classification
- **TCVN Standards**: Automatic classification based on 4 criteria
- **ESA Standards**: Automatic classification based on 4 criteria
- **Physical Quality**: 3-tier grading system (Lo·∫°i 1, 2, 3)

See [my_app/API_README.md](my_app/API_README.md) for detailed API documentation.

## üê≥ Docker Deployment

```bash
# Build and run with Docker Compose
cd my_app
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

## üìã API Endpoints Summary

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information and available models |
| `/predict/all` | POST | Predict all parameters + standards classification |
| `/predict/standards` | POST | TCVN & ESA standards classification only |
| `/predict/origin_classification` | POST | Origin classification (3 regions) |
| `/predict/{model_key}` | POST | Single parameter prediction |
| `/classify/pepper_quality` | POST | Physical quality grading (Lo·∫°i 1, 2, 3) |
| `/health` | GET | Health check |
| `/docs` | GET | Interactive API documentation (Swagger UI) |

## Data Source

- **Input Data**: `mean_by_ma_mau.csv`
  - Contains averaged NIR spectral data by sample code (`ma_mau`)
  - Spectral range: typically 838-1750 nm
  - Quality parameters in the last 5 columns

## How to Use

### 1. Open the Analysis Notebook
```bash
jupyter notebook Code.ipynb
```

### 2. Run the Analysis Sections

The notebook is organized into the following sections:

#### Data Preprocessing
- Load and clean data from `mean_by_ma_mau.csv`
- Apply Savitzky-Golay filter with 2nd derivative
- Handle infinite values and missing data

#### Model Development
For each quality parameter, the notebook:
- Applies PLS variable selection with cross-validation
- Optimizes number of components and wavelength selection
- Fits the final model with range constraints
- Saves the trained model to `mo_hinh/` folder

#### Key Functions
- `pls_variable_selection()`: Optimizes PLS components and wavelength selection
- `RangeRandomizerRegressor`: Wrapper class that constrains predictions within valid ranges
- `print_wavelengths_kept()`: Shows which wavelengths are retained in the final model

### 3. Model Results

Each model section provides:
- Optimal number of PLS components
- Number of wavelengths selected
- Cross-validation R¬≤ and MSE
- Calibration R¬≤ and MSE
- Scatter plot of actual vs predicted values

### 4. Saved Models

Trained models are saved in the `mo_hinh/` folder:
- Models include both the PLS core and range constraints
- Can be loaded using `joblib.load()` for predictions
- Each model is optimized for its specific quality parameter range

## Model Performance Metrics

The analysis reports:
- **R¬≤ Calibration**: Coefficient of determination for training data
- **R¬≤ CV**: Cross-validation coefficient of determination  
- **MSE Calibration**: Mean squared error for training data
- **MSE CV**: Cross-validation mean squared error

## Requirements

```python
numpy
pandas
matplotlib
scikit-learn
scipy
joblib
```

## Usage Example

```python
import joblib
import numpy as np
from scipy.signal import savgol_filter

# Load a trained model
model = joblib.load('mo_hinh/do_am.pkl')

# Prepare new spectral data (apply same preprocessing)
X_new = savgol_filter(X_raw, 15, polyorder=2, deriv=2)
X_new_selected = X_new[:, kept_wavelength_indices]

# Make predictions
predictions = model.predict(X_new_selected)
```

## Notes

- All models use 2nd derivative Savitzky-Golay preprocessing (window=15, polyorder=2)
- Cross-validation uses 10-fold CV with shuffling
- Variable selection removes less important wavelengths to improve model robustness
- Range constraints ensure predictions stay within physically meaningful bounds
- Models are trained on averaged data by sample code to reduce noise

## Contact

For questions about the analysis or models, please refer to the detailed code in `Code.ipynb`.
